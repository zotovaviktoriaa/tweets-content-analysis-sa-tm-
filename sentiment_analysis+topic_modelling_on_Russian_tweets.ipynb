{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment analysis+topic modelling on Russian tweets.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPr4GMm87Yf6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re # regex for cleaning the tweets\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn.svm import SVC\n",
        "!pip install pymorphy2\n",
        "import spacy\n",
        "from spacy.lang.ru import Russian\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сентимент-анализ"
      ],
      "metadata": {
        "id": "hvYSsTBaIH5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#чтение размеченных датасетов\n",
        "dfpos = pd.read_excel('positive.xlsx')\n",
        "dfpos['label'] = 1\n",
        "dfneg = pd.read_excel('negative.xlsx')\n",
        "dfneg['label'] = 0\n",
        "dftagged = pd.concat([dfpos, dfneg], ignore_index=True)"
      ],
      "metadata": {
        "id": "ivVc9TCs9ClU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#функция очистки данных\n",
        "nlp = Russian()\n",
        "\n",
        "\n",
        "def my_tokenizer(text):\n",
        "  text = re.sub(\"[A-Za-z0-9!#$%&';:*+,./<=>?@[\\]^_`()«»...{|}~—\\\"\\-]+\",\"\",text)\n",
        "  stopWords = stopwords.words('russian')\n",
        "  stopWords.extend(['мтс', 'билайн', 'мегафон', 'компании', 'пожалуйста','бизнес', 'теле', 'это', 'мочь', 'который', 'здравствуйте', 'также', 'вообще', 'компания', 'вымпелком', 'ростелеком', 'тело', 'стать', 'очень', 'г'])\n",
        "  doc = nlp(text.strip())\n",
        "  for token in doc:\n",
        "    print(token, token.lemma, token.lemma_)\n",
        "  tokens = [token.lemma_ for token in doc]\n",
        "  words_clear = []\n",
        "  for w in tokens:\n",
        "      if w.isalpha() ==True and w.lower() not in stopWords:\n",
        "          words_clear.append(w.lower())\n",
        "\n",
        "  return words_clear"
      ],
      "metadata": {
        "id": "JT2SeCvT9mfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dftagged.rename(columns={\"Column4\": \"text\"},inplace=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(dftagged['text'], dftagged['label'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "UQCqgbmu-BLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#тест Байесовского классификатора с BOW \n",
        "vec = CountVectorizer(ngram_range=(1,2), tokenizer = my_tokenizer)\n",
        "bow = vec.fit_transform(X_train)\n",
        "bow_test = vec.transform(X_test)\n",
        "\n",
        "clf = MultinomialNB()\n",
        "clf.fit(bow, y_train)\n",
        "pred = clf.predict(bow_test)\n",
        "print(classification_report(y_test, pred))"
      ],
      "metadata": {
        "id": "ZXem85en-1VC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#тест Байесовского классификатора с TF-IDF\n",
        "vec = TfidfVectorizer(ngram_range=(1,2), tokenizer = my_tokenizer)\n",
        "tfidf = vec.fit_transform(X_train)\n",
        "tfidf_test = vec.transform(X_test)\n",
        "\n",
        "clf = MultinomialNB()\n",
        "clf.fit(tfidf, y_train)\n",
        "pred = clf.predict(tfidf_test)\n",
        "print(classification_report(y_test, pred))"
      ],
      "metadata": {
        "id": "eOqrO-wg-yCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#тест SVM с BOW\n",
        "vec = CountVectorizer(ngram_range=(1,2), tokenizer = my_tokenizer)\n",
        "bow = vec.fit_transform(X_train)\n",
        "bow_test = vec.transform(X_test)\n",
        "\n",
        "clf = svm.SVC()\n",
        "clf.fit(bow, y_train)\n",
        "pred = clf.predict(bow_test)\n",
        "print(classification_report(y_test, pred))"
      ],
      "metadata": {
        "id": "cbpKfzHt_FCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#тест SVM с TF-IDF\n",
        "vec = TfidfVectorizer(ngram_range=(1,2), tokenizer = my_tokenizer)\n",
        "tfidf = vec.fit_transform(X_train)\n",
        "tfidf_test = vec.transform(X_test)\n",
        "\n",
        "clf2 = svm.SVC()\n",
        "clf2.fit(tfidf, y_train)\n",
        "pred = clf.predict(tfidf_test)\n",
        "print(classification_report(y_test, pred))"
      ],
      "metadata": {
        "id": "lZr8P75A-_FJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#чтение неразмеченных датасетов по компаниям\n",
        "beeline = pd.read_excel('beeline.xlsx', header=None)\n",
        "megafon = pd.read_excel('megafon.xlsx',header=None)\n",
        "mts = pd.read_excel('mts.xlsx',header=None)\n",
        "tele2 = pd.read_excel('tele2.xlsx',header=None)\n",
        "beeline.rename(columns={beeline.columns[0]: \"text\"}, inplace=True)\n",
        "megafon.rename(columns={megafon.columns[0]: \"text\"}, inplace=True)\n",
        "mts.rename(columns={mts.columns[0]: \"text\"}, inplace=True)\n",
        "tele2.rename(columns={tele2.columns[0]: \"text\"}, inplace=True)\n",
        "beeline.rename(columns={beeline.columns[1]: \"date\"}, inplace=True)\n",
        "megafon.rename(columns={megafon.columns[1]: \"date\"}, inplace=True)\n",
        "mts.rename(columns={mts.columns[1]: \"date\"}, inplace=True)\n",
        "tele2.rename(columns={tele2.columns[1]: \"date\"}, inplace=True)"
      ],
      "metadata": {
        "id": "qPIzcHcy_j3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#предсказывание классов по компаниям\n",
        "beeline_bow = vec.transform(beeline.text)\n",
        "beeline['labels'] = clf.predict(beeline_bow)\n",
        "megafon_bow = vec.transform(megafon.text)\n",
        "megafon['labels'] = clf.predict(megafon_bow)\n",
        "mts_bow = vec.transform(mts.text)\n",
        "mts['labels'] = clf.predict(mts_bow)\n",
        "tele2_bow = vec.transform(tele2.text)\n",
        "tele2['labels'] = clf.predict(tele2_bow)"
      ],
      "metadata": {
        "id": "sZq0_i-ZAR0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#объединение для построения общего графика по классам и компаниям, в работе реализовано в Power BI \n",
        "dflab = pd.concat([beeline, megafon, mts, tele2])\n",
        "beeline['company'] = 'Билайн'\n",
        "megafon['company'] = 'Мегафон'\n",
        "mts['company'] = 'МТС'\n",
        "tele2['company'] = 'Теле2'\n",
        "fig = plt.figure(figsize = (10, 5))\n",
        "sns.set_style('white')\n",
        "sns.set_style('ticks')\n",
        "plt.title('Overall sentiments')\n",
        "sns.countplot(x = 'company', hue='labels',  data =dflab, palette = ['red', 'green'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M80JTIxeBYfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Тематическое моделирование"
      ],
      "metadata": {
        "id": "GDSk_48dDZ2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "import gensim.corpora as corpora\n",
        "from pprint import pprint\n",
        "import matplotlib.colors as mcolors"
      ],
      "metadata": {
        "id": "HfbTb1cSCNXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#предобработка и очистка данных\n",
        "beeline['posttext'] = beeline.text.apply(my_tokenizer)\n",
        "mts['posttext'] = mts.text.apply(my_tokenizer)\n",
        "megafon['posttext'] = megafon.text.apply(my_tokenizer)\n",
        "tele2['posttext'] = tele2.text.apply(my_tokenizer)"
      ],
      "metadata": {
        "id": "59SA2pWzDWgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#создание облака слов по классам для каждой компании на примере негативных отзывов Билайн (Рис 8)\n",
        "stopWords = set(stopwords.words('russian'))\n",
        "text = \" \".join(str(review) for review in beeline[beeline.labels == 0].posttext)\n",
        "cloudtext = re.sub(\"[A-Za-z0-9!#$%&':*+,./<=>?@[\\]^_`()«»...{|}~—\\\"\\-]+\",\" \",text)\n",
        "wordcloud = WordCloud(stopwords=stopWords, max_words=50, width=1600, height=800).generate(cloudtext)\n",
        "\n",
        "plt.figure(figsize=(40,30))\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-FUuS67UDj5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#подготовка к LDA\n",
        "words = beeline[beeline.labels == 0].posttext.values.tolist()\n",
        "id2word = corpora.Dictionary(words)\n",
        "#создание корпуса\n",
        "texts = words\n",
        "#матрица частот слов в документах\n",
        "corpus = [id2word.doc2bow(text) for text in texts]"
      ],
      "metadata": {
        "id": "YYevTiliD1qP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#скачивание пакетов для LDAMallet\n",
        "!wget http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
        "!unzip mallet-2.0.8.zip"
      ],
      "metadata": {
        "id": "lkvGqDE-Egnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mallet_path = '/content/mallet-2.0.8/bin/mallet'\n",
        "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=6, id2word=id2word)\n",
        "#отображение сгенерированных тем\n",
        "pprint(ldamallet.show_topics(formatted=False))"
      ],
      "metadata": {
        "id": "YHpEU_bwFTwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#составление облаков слов по сгенерированным темам (Рис 12)\n",
        "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]  \n",
        "\n",
        "cloud = WordCloud(\n",
        "                  background_color='black',\n",
        "                  width=2500,\n",
        "                  height=1800,\n",
        "                  max_words=10,\n",
        "                  colormap='tab10',\n",
        "                  color_func=lambda *args, **kwargs: cols[i],\n",
        "                  prefer_horizontal=1.0)\n",
        "\n",
        "topics = ldamallet.show_topics(formatted=False)\n",
        "\n",
        "fig, axes = plt.subplots(3, 2, figsize=(10,10), sharex=True, sharey=True)\n",
        "\n",
        "for i, ax in enumerate(axes.flatten()):\n",
        "    fig.add_subplot(ax)\n",
        "    topic_words = dict(topics[i][1])\n",
        "    cloud.generate_from_frequencies(topic_words, max_font_size=300)\n",
        "    plt.gca().imshow(cloud)\n",
        "    plt.gca().set_title('Topic ' + str(i), fontdict=dict(size=16))\n",
        "    plt.gca().axis('off')\n",
        "\n",
        "\n",
        "plt.subplots_adjust(wspace=0, hspace=0)\n",
        "plt.axis('off')\n",
        "plt.margins(x=0, y=0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dL7Ri7AIFfF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#расчет весов сгенерированных тем в коллекции документов\n",
        "tm_results = ldamallet[corpus]\n",
        "corpus_topics = [sorted(topics, key=lambda record: -record[1])[0] for topics in tm_results]\n",
        "corpus_topic_df = pd.DataFrame()\n",
        "corpus_topic_df['Dominant Topic'] = [item[0] for item in corpus_topics]\n",
        "corpus_topic_df['Contribution %'] = [round(item[1]*100, 2) for item in corpus_topics]\n",
        "dominant_topic_df = corpus_topic_df.groupby('Dominant Topic').agg(\n",
        "                                  Doc_Count = ('Dominant Topic', np.size),\n",
        "                                  Topic_Weight = ('Dominant Topic', np.size)).reset_index()\n",
        "\n",
        "dominant_topic_df['Topic_Weight'] = dominant_topic_df['Topic_Weight'].apply(lambda row: round((row*100) / len(corpus), 2))"
      ],
      "metadata": {
        "id": "RgZ5SwhmF_Qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#график распределения весов тем в коллекции для каждой компании и класса на примере негативных отзывов Билайн \n",
        "fig = plt.figure(figsize = (10, 5))\n",
        "sns.set_style('dark')\n",
        "sns.set_style('ticks')\n",
        "plt.title('Topics distribution over Beeline Negative Tweets')\n",
        "sns.barplot(x = 'Dominant Topic', y = 'Topic_Weight',  data =dominant_topic_df, palette = 'magma')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ij2JpJ02GnhM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}